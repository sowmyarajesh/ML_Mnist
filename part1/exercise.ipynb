{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-g_lHBMaMtm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append(\"..\")\n",
        "from utils import *\n",
        "from linear_regression import *\n",
        "from svm import *\n",
        "from softmax import *\n",
        "from features import *\n",
        "from kernel import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def IdentityMatrix(n):\n",
        "    imat = []\n",
        "    for r in range(n):\n",
        "        row = []\n",
        "        for c in range(n):\n",
        "            if r==c:\n",
        "                row.append(1)\n",
        "            else:\n",
        "                row.append(0)\n",
        "        imat.append(row)\n",
        "    return imat\n",
        "    \n",
        "def DiagonalMatrix(n,l):\n",
        "    dmat = []\n",
        "    for r in range(n):\n",
        "        row = []\n",
        "        for c in range(n):\n",
        "            if r==c:\n",
        "                row.append(l)\n",
        "            else:\n",
        "                row.append(0)\n",
        "        dmat.append(row)\n",
        "    return dmat\n",
        "def H_Func(n):\n",
        "    one = np.ones(n)\n",
        "    i = IdentityMatrix(n)\n",
        "    H = np.subtract(i, np.dot(1/n, np.matmul(one, np.transpose(one))))\n",
        "    return H\n",
        "\n",
        "def gramMatrix(vectorList):\n",
        "    V = np.array(vectorList)\n",
        "    G = V.dot(V.T)\n",
        "    return G\n",
        "\n",
        "def eigenValues(vector):\n",
        "    w,v  = np.linalg.eig(vector)\n",
        "    return np.round(w,3)\n",
        "\n",
        "def eigenVector(vector):\n",
        "    w,v  = np.linalg.eig(vector)\n",
        "    return np.round(v,3)"
      ],
      "metadata": {
        "id": "nVDhlFYQcsck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLa8ogGQaMto"
      },
      "source": [
        "\n",
        "#######################################################################\n",
        "# 1. Introduction\n",
        "#######################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki3wc7XJaMtq"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data:\n",
        "train_x, train_y, test_x, test_y = get_MNIST_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqQVtMMgaMtq"
      },
      "source": [
        "To solve the linear regression problem, you recall the linear regression has a closed form solution:\n",
        "\n",
        "```\n",
        "    theta = ((transpose(X).X+lambda* I) ^ -1). transpose(X).Y\n",
        "```\n",
        "\n",
        "where I = identity matrix\n",
        "\n",
        "lambda = regularization parameter\n",
        "\n",
        "X = input feature\n",
        "\n",
        "Y = output label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn8aKLjUaMtq"
      },
      "outputs": [],
      "source": [
        "def closed_form(X, Y, lambda_factor):\n",
        "    \"\"\"\n",
        "    Computes the closed form solution of linear regression with L2 regularization\n",
        "\n",
        "    Args:\n",
        "        X - (n, d + 1) NumPy array (n datapoints each with d features plus the bias feature in the first dimension)\n",
        "        Y - (n, ) NumPy array containing the labels (a number from 0-9) for each\n",
        "            data point\n",
        "        lambda_factor - the regularization constant (scalar)\n",
        "    Returns:\n",
        "        theta - (d + 1, ) NumPy array containing the weights of linear regression. Note that theta[0]\n",
        "        represents the y-axis intercept of the model and therefore X[0] = 1\n",
        "    \"\"\"\n",
        "    # create Identity matrix for the number of data points. \n",
        "    I = \n",
        "    step1 = np.dot(X.T,X)\n",
        "    step2 = np.add(step1, np.dot(lambda_factot, I))\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('LD')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31c4a5216d1b70edb8ccadb0033ed466ad602c2eadb1aba86d4896a8d7ddf022"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}